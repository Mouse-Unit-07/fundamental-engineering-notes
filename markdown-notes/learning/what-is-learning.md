# What is Learning

- Notes about learning as a process, not advice for how to learn

## Index

- [Index](#index)
- [Active vs Receptive Learning](#active-vs-receptive-learning)
- [Adjusting Mental Model Parameters](#adjusting-mental-model-parameters)
- [Automatization](#automatization)
- [Bootstrapping](#bootstrapping)
- [Bottom Up vs Top-Down Learning](#bottom-up-vs-top-down-learning)
- [Brain Breakdown](#brain-breakdown)
- [Combinatorial Explosion](#combinatorial-explosion)
- [Consolidation](#consolidation)
- [Curiosity](#curiosity)
- [Forgetting Cues](#forgetting-cues)
- [Four Pillars of Learning](#four-pillars-of-learning)
- [Hexagons in Neuronal Maps](#hexagons-in-neuronal-maps)
- [Humans vs Machines](#humans-vs-machines)
- [Memory Traces](#memory-traces)
- [Minimizing Errors](#minimizing-errors)
- [Myths](#myths)
- [Nature vs Nurture](#nature-vs-nurture)
- [Neuronal Recycling](#neuronal-recycling)
- [Neuroplasticity](#neuroplasticity)
- [Neurotransmitters](#neurotransmitters)
- [Paying Attention](#paying-attention)
- [Rescorla-Wagner Theory](#rescorla-wagner-theory)
- [Retrieval vs Learning Capacity](#retrieval-vs-learning-capacity)
- [Sleep](#sleep)
- [Statisticians](#statisticians)
- [Synaptic Plasticity](#synaptic-plasticity)
- [Teaching](#teaching)
- [Thomas Bayes](#thomas-bayes)
- [Types of Memory](#types-of-memory)
- [What We're Born With](#what-were-born-with)
- [Why We Learn](#why-we-learn)

## Active vs Receptive Learning

- Active mode
  - When we act on our own and form hypotheses, perform tests, and reflect
  - Without active engagement, learning is reduced to little or nothing
- Receptive mode
  - When we absorb what someone tells us without verifying
  - This has led to what society is today- no one has the time to reinvent everything people before them have done
- The balance of active and receptive mode are critical to perform optimally

## Adjusting Mental Model Parameters

- As in, Bayes' theorem and his idea about how learning is a constant feedback loop of adjusting parameters
- Each mental model is associated w/ parameters, which we are capable of dynamically modifying as we receive new inputs

## Automatization

- Whether it's reading, typing, or playing an instrument, repeating practices will get the brain to consolidate those skills to long-term memory, and modify neural circuits to automatically/efficiently perform whatever you're practicing
- Our brains can do this, because we need to free cortex resources
  - "Executive control" is always a bottleneck- we can't perform multiple tasks that all require a conscious mind
  - The brain modifies itself so that frequently performed tasks can be done unconsciously

## Bootstrapping

- Originates from Baron Munchausen's _Adventures_ where he tried to fly away by pulling on his bootstraps
- "Bootstrapping" refers to when a system performs work to internally refine itself

## Bottom Up vs Top-Down Learning

- We do both bottom-up and bottom-down learning
- Bottom-Up
  - Learning by reacting to parameters/inputs as we interface w/ our environment
- Top-Down
  - Learning provided information acquired from the environment, or generated internally (in your sleep, etc)

## Brain Breakdown

- Memory and knowledge is a collection of at birth 100 billion nerve cells (neurons) and neural pathways (synapses)
- A little after birth we undergo "an exuberant burst of synapse formation" where the brain starts wiring itself together
  - Neurons sprout branches called axons to reach nubs on other neurons called dendrites
  - An axon/dendrite connection is a synapse
  - These connections allow for everything under human intellectual ability
  - Message to each axon is electrical, and messages are converted from electrical -> chemical -> electrical as messages go from axon to dendrite to axon
- Synapse count peaks when we're 1 or 2 years old- 50% higher than the average number we have as adults
- Synapse count rises until puberty (age 16 or so), and then after that they start to slowly decline- this is called synapse pruning
- We end w/ a total of 150 million synapses or so

## Combinatorial Explosion

- W/ all the inputs we have and the numerous observations that may or may not associated w/ "success", it's not possible to compute every combination of possibilities
- We break down the problem by organizing thoughts into a hierarchical/multilevel model for each sensory system
- Each layer has a small window to worry about, where patterns are recognized as abstractions to be translated into mental models to be stored in long-term memory
- Exploring the space of possibilities
  - When considering each possibility, a learning entity can get stuck from the lack of further positive feedback from testing
  - Injection of some randomness then helps find the best parameters- whether it's changing the order, adding noise, using a subset
  - ...maybe that's why we're not so perfect/logical as you would expect from billions of years worth of evolution- the randomness has helped us survive
- Overfitting
  - > With four parameters I can fit an elephant, and with five I can make him wiggle his trunk.
    - John von Neumann
    - This is to say that overfitting is an issue- overanlyzing a set of data doesn't necessary help provide any useful generalizations
  - Sometimes taking away parameters is effective- generalizing datasets helps prevent overfitting to unnecessary frills or noises
- Leaning on prior knowledge
  - The search space can be shaved down provided patterns you've already recognized as heuristics for what to search for next
  - ...That's the whole point of remembering things- so we don't have to repeat the same processing, and to better interface w/ the world in real-time
  - Prior knowledge / patterns are stored as abstract mental models as opposed to hard data to avoid overfitting
- Finding underlying rules
  - "Learning" on a broad scale is to find the underlying rules that govern the way things work
  - We need multiple inputs that we're familiar w/ when we're testing another- this is why body language is crucial for children to learn languages

## Consolidation

- Process of strengthening mental representations for long-term memory
- New memory traces are susceptible to change- through consolidation the brain reorganizes and stabilizes memory traces
- We never stop learning- something's that's already been consolidated can then be strengthened w/ more efficient neural circuits

## Curiosity

- Acquisition of information that's surprising (as in, violates current understanding) is associated w/ the activation of a dopamine circuit
- The opposite of curiosity is boredom- we're naturally uninclined to experience repetitive events, and events that are too far off of one's current understandings
- Things that are just the right amount surprising are in the middle between completely incomprehensible and repetitive/understood
- Curiosity correlates to memory- the more curious you are about something, the more likely you'll remember it
- Metacognition
  - Hold up, but that means we need to know what we don't know right?
  - Cognition over cognition is called "metacognition"- we have a system that keeps track of what we know and don't know
- Losing curiosity
  - Lack of cognitive stimulation
    - Being fed old information over and over gets you tired
  - Learning that you're not successful at learning
    - Being told that you're not successful over and over teaches you that you can't learn
  - Punished for being curious
    - Telling children to shut up and stay still in a corner so they don't come in to your peripheral vision doesn't help
  - The solution is to remind students that they're capable, and show them how the material is tailored to their level
    > When you give such a gadget to children without saying anything, you immediately set off their curiosity: they explore, rummage, forage, and poke around until they find most of the hidden rewards. Now, take a new group of kindergartners and put them into the passive, receptive pedagogical mode. All you have to do is give them the object while saying, "Look, let me show you my toy. This is what it does..." and then play the music box, for instance. One might think that this would stimulate the children's curiosity... but it has the opposite effect: exploration massively decreases following this kind of introduction. Children seem to make the (often correct) assumption that the teacher is trying to help them as much as possible, and that he has therefore introduced them to all the interesting functions of the device. in this context, there is no need to search: curiosity is inhibited.
    >
    > [...] Further experiments show that children take into account the teacher's past behavior. When a teacher always makes exhaustive demonstrations, students lose curiosity. If the teacher demonstrates one of the functions of the new toy, children do not explore all its facets, because they think that the teacher has already explained everything there is to know. If, on the contrary, the teacher gives evidence that he doesn't always know everything, then the children keep searching.
  - _How We Learn: Why Brains Learn Better Than Any Machine... For Now_
- Ask students questions, show them that you don't know everything, and don't override their experimenting

## Forgetting Cues

- We forget cues to our mental models so that we can remember new cues

## Four Pillars of Learning

- Four mechanisms that make our brains great at learning:
- **Attention**
  - We have neural circuits to select/amplify/propagate signals that we decide are relevant
  - This allows us to choose what's impactful on our memory, and to handle information saturation at real-time
  - 3 major attention systems:
    - Alerting
      - Indicates when to pay attention, and adapts our level of vigilance
    - Orienting
      - Indicates what to pay attention to, and amplifies an object of interest
    - Executive attention
      - Decides how to process the information you're paying attention to, selects relevant processes, and controls process execution
      - Closely tied to management of "working memory"
      - Decision making for how to process real-time data is slow- it's called the "central bottleneck"
      - No matter how hard we try, we only have 1 core each for activities that demand conscious thought... We can try and multithread, but there are significant delays
        - You might as well just do one thing at a time if quality matters
        - Distractions hinder processing- doing multiple things at once is like manually injecting a distraction into whatever else you're trying to do
  - ...We're limited in how much we can pay attention, and we're unaware of how unaware we are
    - Thus we can't stay focused on doing social studies homework for more than a handful of hours straight, and start an argument about whether someone did something in a movie that you were both sitting down for 2 seconds ago
- **Active engagement**
  - Again, we're naturally built to cycle through forming hypothesis, testing, and building/revising assumptions about the world
  - We make use of our natural curiosity and internal motivators to learn for survival
  - Without active engagement, you won't have any fundamental base understandings of the world to accept what others try to teach in addition to what you already have via receptive learning
  - Learning associated w/ peripheral usage is impossible without active engagement- we move around and take in inputs to know how to interface w/ the world
- **Error feedback**
  - Error signals propagate across the brain whenever something surprises us
  - W/ these signals, we update our mental models or stabilize them if they're reinforced
  - Brain regions can be thought of as a hierarchy of predictive systems that pass signals between each other in response to error signals that can't be explained
  - Each brain region is responsible for a different type of peripheral input error
  - Error feedback isn't punishment
    - There's no need for pain to get the brain to receive an error signal
    - There just needs to be an unresolved error signal for the brain to start calculating prediction error to create a new prediction
- **Consolidation**
  - Transferring information from short-term memory to long-term memory frees up resources for more learning
  - Repetition (recalling/replaying memories) both when you're awake and asleep reinforces consolidation

## Hexagons in Neuronal Maps

- Hexagons emerge naturally when things transition from a "hot" state and cool down / stabilize
- When the brain develops, the disorganized neurons settle down into organized grid cells, where hexagons develop naturally

## Humans vs Machines

- People are better than machines (for now) thanks to:
- Data-efficient learning
  - Neural networks need many data points to have some intuition for a particular domain
  - Pokemon would take hundreds or thousands of hours for a machine to start playing effectively from scratch, but a kid can probably get going in a couple hours
- Social learning
  - People voluntarily share information
  - Neural networks have a hard time sharing data when everything is encrypted in synaptic weights
- One-trial learning
  - When we're accustomed to a particular domain, we at best only need a single trial to learn something new
  - If we're thrown an unfamiliar verb in English, we can conjugate it and start using it provided we know English
- Generalization and language of thought
  - Humans are able to generalize and abstract thoughts to find underlying rules that govern the way things work
  - Whether it's math, language, engineering, music, etc, we have a nice learning algorithm to generalize concepts and reapply them
- Composition
  - Learned skills are subroutines that can be integrated into other skills

## Memory Traces

- Perceptions -> chemical and electrical changes in your brain that represent some mental representation
- ^This process is called "encoding", and the new representations are called "memory traces"

## Minimizing Errors

- Each layer in the hierarchy/organizations of thoughts that is created by our cortex is capable of suggesting an observed pattern, which is then propagated to other layers and eventually rejected or consolidated
- Learning is then a cycle of minimizing errors across these repetitive cycles of hypothesis generation, testing, and consolidation
- Optimizing a reward function
  - In a video game we have clear parameters to try and maximize, but life doesn't provide you w/ a list parameters to min-max (other than the number of hours spent reading manga- clearly worthy of maximizing)
  - We not only need to optimize the way output parameters are configured, but we also need to modify what input parameters to consider and each of their weights when trying to reach some goal

## Myths

- Digital native
  - Mastery of technology is superficial- no new generation is born w/ an innate ability to work w/ electronics
- Learning styles
  - No empirical evidence- no reason to believe in any of it
  - > What is true is that some teaching strategies work better than others- but when they do, this superiority applies to all of us, not just a subgroup. For instance, experiments show that all of us have an easier time remembering a picture than a spoken word, and that our memory is even better when the information is conveyed by both modalities- an audiovisual experience. Again, this is the case for all children. There is simply no evidence in favor of the existence of subtypes of children with radically different learning styles, such that type A children learn better with strategy A, and type B children with strategy B. For all we know, all humans share the same learning algorithm.
    - _How We Learn: Why Brains Learn Better Than Any Machine... For Now_
  - > What about all the special education books and software that claim to tailor education to each child's needs? Are they worthless? Not necessarily. Children do vary dramatically, not in learning style, but in the speed, ease, and motivation with which they learn.
    - _How We Learn: Why Brains Learn Better Than Any Machine... For Now_

## Nature vs Nurture

- The historical argument as to whether we come born w/ intelligence or gain it throughout our lives
- The answer is both- we're hardwired via evolution on some fronts, and are made to adapt on others
- Nature
  - "Priors" in Bayesian terms
- Nurture
  - "Posterior"- revision on hypothesis from inferences made over experiences

## Neuronal Recycling

- To learn is to reuse an existing brain circuit- or to fit new concepts in circuits that are flexible enough
- We're not necessarily made to solve algebra problems or write poems, but we can reuse particular regions of the brain that are flexible enough to perform each non-survival-essential task
  - Reading recycles vision and spoken language circuits
- This is why learning is much better when new concepts build on preexisting concepts you understand

## Neuroplasticity

- Brain structures are plastic/mutable, and something that reorganizes itself upon you completing tasks
- This plastic/mutable feature declines as you age, but neuroplasticity is always true

## Neurotransmitters

- Chemical messengers transmitted between neurons- the data form factor when traveling between neurons
- Ex:
  - Acetylcholine
    - Controls muscle contraction, learning, memory
    - Used at neuromuscular regions
    - ...Loss of this is tied to Alzheimer's
  - Dopamine
    - Reward, pleasure, motivation, movement control
    - Too little causes Parkinson's disease, too much causes schizophrenia-like effects
  - Serotonin
    - Mood, sleep, appetite, emotion balance
    - Too low causes depression/anxiety, where anti-depressants are made to treat
  - Norepinephrine (noradrenaline)
    - Alertness attention, fight or flight
    - Raises heart rate, blood pressure- linked to stress response
  - GABA (gamma-aminobutyric acid)
    - Main inhibitory transmitter in the brain
    - Calms neural actiivty
    - Too low causes anxiety and seizures
  - Glutamate
    - Main excitatory transmitter
    - Involved in learning/memory
    - Too much causes excitotoxicity, aka neuron damage
  - Endorphins
    - Natural painkillers and mood enhancers
    - Released during exercise, laughter, pain
  - Histamine
    - Wakefulness, immune response
    - Plays a role in inflammation and arousal
- These neurotransmitters are used to put our inputs through a feedback loop to modify the current mental/memory state and to make our next decisions

## Paying Attention

- One of the "4 pillars of learning"
- Concentration / self-control isn't available to children
- It's available once your prefrontal cortex has matured- so 15-20 years
- Many mistakes and illusions occur as a result of lacking attention
- Social attention sharing
  - We pay attention when others pay attention
  - This is apparent in children that seek eye contact before turning to what you're prompting a child to see

## Rescorla-Wagner Theory

- Aka, "classical conditioning"
- The brain uses sensory inputs to predict the probability of a stimulus:
  - Brain first generates a prediction w/ a weighted sum of sensory inputs
  - Difference in prediction and actual stimulus received is calculated
    - This is "prediction error"- the measure of surprise associated w/ each stimulus
  - Surprise signal is used to correct internal mental model in proportion to the strength of the stimulus and value of prediction error
- This improved on the "associative learning" concept
  - Claimed that peripheral inputs were just directly associated w/ stimulus, as opposed to being used to update mental models and make predictions

## Retrieval vs Learning Capacity

- Our "learning" bottleneck is retrieval capacity
- We can infinitely learn new material, but recalling it when we want it is the hard part
- ...When you pass through a physics textbook and you open it again a year later, you might recall some words that follow what you're reading, but if you're blindly told to write out the contents of the textbook you'd definitely be screwed
- This is also why we like multiple choice over fill in the answer questions (aside from having a random chance of being correct)- the answers serve as keys/cues to what you have in memory
- This is helpful for our survival- real-time processing gets too hard if there's so much information readily available to you

## Sleep

- Practice is effective on the long term when it's spread out- this is because of sleep
- When you sleep, memories are consolidated to long-term memory
  - Important events are replayed, and transferred to higher regions of the brain
  - When thoughts are replayed, the brain is essentially looking for what's important- the patterns that make sense and are important enough to store
  - This frees up cortex resources for new work, while keeping what's important as generalized/abstracted mental models
  - Working w/ what's already been received this way is top-down learning
  - When the parameters for a mental model and their consequences are already known, it's a lot easier for the brain to find the links between parameters and consequences as opposed to doing such processing in real-time
- Sleep isn't just for brain rest/inactivity or for garbage collection of physical waste in the brain

## Statisticians

- We're all hardwired from birth to be "statisticians" to help our decision making
- We weigh one decision against another, and choose what's best for ourselves
- Even when it's not something not directly related to our benefit, we're made to cycle through hypothesis building, testing, and making assumptions to build an understanding of the world and our surroundings
  - Acquiring information is naturally incentivized by hormones- we're pleased when something is both unexpected, and when that something builds on something we already know

## Synaptic Plasticity

- The developing brain undergoes a "sensitive period", aka a period of "synaptic plasticity"
  - This refers to a period when synapse development peaks- this pattern of synapse increase and decrease is varies across different regions of the brain
  - Some regions peak at age 1 or 2, some peak at early adolescence
  - The prefrontal cortex is last to stabilize at age 5-10
  - W/ peripheral regions at the bottom of the hierarchy and abstract processing at the top, the lower regions are what stabilize first
- During synaptic plasticity, useless synapses are quickly pruned away, and useful ones are quickly reinforced
- Learning gets harder and harder as time passes after the peak- we keep losing synapses over the course of our lives
- On the other hand, we always remember what we learned as children- there's always a strong trace of our origins regardless of how much we overwrite
- Neuroplasticity also never disappears completely- people in their 50s and 60s are capable of learning to play new instruments or speak 2nd languages

## Teaching

- Teaching is to pay attention to how someone else is perceiving inputs
- Discovery-based teaching
  - Decades of study indicate that leaving students to reinvent the wheel on their own isn't effective
  - Students shouldn't be left on their own without any rails or feedback to lean on when instructed to learn something
- Teachers need to lay down exercises for students to test, and then provide feedback for error correction to get closer to the goal step by step
- > In the words of psychologist Richard Mayer, who reviewed this field, the best success is achieved by "methods of instruction that involve cognitive activity rather than behavioral activity, instructional guidance rather than pure discovery, and curricular focus rather than unstructured exploration." Successful teachers provide a clear and rigorous sequence that begins with the basics. They constantly assess their students' mastery and let them build a pyramid of meaning.
  - _How We Learn: Why Brains Learn Better Than Any Machine... For Now_
- Grades
  - Grades aren't helpful most of the time, because they're slow and don't provide any error correction
  - Getting into a pit of bad grades and falling behind is like playing a merciless Dark Souls game w/ some mod that somehow lets you progress to harder and harder parts of the game all while you still don't know why you can't clear the first part of the game- even Dark Souls fans wouldn't do that to themselves
  - The objective is to tell students why they got things wrong, and maybe teach them how they can test themselves if there's no capacity to provide students w/ exercises that test students without permanent negative consequences

## Thomas Bayes

- Thomas Bayes was a statistician and minister
- Bayes' theorem (yea the one we've used over and over in math) models how we are (mayhaps) wired to learn, and is used machine learning

```
P(H|E) =  (P(E|H) * P(H))/ P(E)
- H = hypothesis
- E = evidence
- P(H) = prior probability of the hypothesis
- P(E|H) = probability of evidence if hypothesis is true
- P(H|E) = probability ("posterior") of hypothesis after observing evidence
```

- The main relevant idea w/ respect to learning is how a constant generation of hypotheses and management of probabilities provided a constant wave of changing inputs serves as an effective learning algorithm, over just managing one parameter/hypothesis at a time
- A learning entity needs to constantly revise prior assumptions and update the likelihood of potential new assumptions and then choose a new assumption(s) to use when decision making / performing new tests
- Alan Turning used Bayesian theory to decrypt the ENIGMA in WWII
  > Inspector Gregory: Is there any other point to which you would wish to draw my attention?
  >
  > Sherlock Holmes: To the curious incident of the dog in the night-time
  >
  > Inspector Gregory: The dog did nothing in the night-time
  >
  > Sherlock Holmes: That was the curious incident
  - Sherlock Holmes in "Silver Blaze"

## Types of Memory

- Working memory
  - Memory holding mental representations of inputs from active peripheral regions of the brain
  - Holds information for a few seconds
- Episodic memory
  - The "hippocampus"
  - What records a history of our lives- without this region you'll forever live in the present unable to operate
- Semantic memory
  - Permanent memory- abstractions and generalizations that are transferred and processed from episodic memory
- Procedural memory
  - Compact, unconscious recording of patterns in routine activity
  - Muscle memory
  - W/ this, and enough practice, individuals can learn to do new things even w/o episodic memory...

## What We're Born With

- Object concept
  - Concept that the world is composed of rigid objects, and some basic physics to interface w/ said rigid objects
- Number sense
  - Concept of quantity and basic arithmetic
- Knowledge of animals and people
  - Animate objects and associated capability to move, and inanimate objects and how they stay put
- Face perception
  - We're hardwired to recognize faces, from 3 dots in a pyramid structure to recognizing two eyes and a mouth
- Language instinct
  - From birth we're hardwired to acquire spoken language

## Why We Learn

- Because it's not possible to encode all the information about the world in DNA
- Human genome can be reduced to ~750MB... which doesn't take into account redundancies in DNA
- It's also a lot more advantageous to adapt to each of our specific environments instead of hard wiring ourselves
  - We've also "learned" (evolved to account for) what doesn't change over the course of generations- our physical features are dependent on gravity, propagation of light, etc
- > Learning is the triumph of our species. In our brain, billions of parameters are free to adapt to our environment, our language, our culture, our parents, our food.... These parameters are carefully chosen: over the course of evolution, the Darwinian algorithm carefully delineated which brain circuits should be pre-wired and which should be left open to the environment. In our species, the contribution of learning is particularly large since our childhood extends over many more years than it does for other mammals. And because we possess a knack for language and mathematics, our learning device is able to navigate vast spaces of hypotheses that recombine into potentially infinite sets- even if they are always grounded in fixed and invariable foundations inherited from evolution.
  - _How We Learn: Why Brains Learn Better Than Any Machine... For Now_
